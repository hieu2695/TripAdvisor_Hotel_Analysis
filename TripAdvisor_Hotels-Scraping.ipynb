{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libararies\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.parse\n",
    "from urllib.parse import urljoin\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the base links of TripAdvisor and create lists to store links later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlmain = \"https://www.tripadvisor.com/Hotels-g191-United_States-Hotels.html\" # main page of U.S hotels \n",
    "base_url = \"https://www.tripadvisor.com\" # base link of the TripAdvisor website\n",
    "\n",
    "list_local = [] # store url for the first pages of top 100 U.S cities of hotel services\n",
    "full_list_local = [] # store url for first 5 pages of top 100 cities # 500 pages in the total\n",
    "list_hotel = [] # store url for hotels in these 500 pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the hotel links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scrape 100 location links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I will scrape the links of 100 locations (5 pages, 20 locations/page). <br> \n",
    "* Due to the different structure of the first page, I have to write a separate code for it. <br> \n",
    "* For other pages, I will use the for loop to retrieve the links. <br> \n",
    "* The 100 location links will be stored in the list_local. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the links in the first page and store them in list_local\n",
    "html = requests.get(urlmain)\n",
    "soup = BeautifulSoup(html.content, 'lxml')\n",
    "for item in soup.find_all(\"a\", attrs={\"class\":\"linkText\"}):\n",
    "    full_loc_url = []\n",
    "    loc_url = item.get(\"href\") # get all the href containing the links for the location\n",
    "    full_loc_url = urljoin(base_url,loc_url) # join the href links with the base link of TripAdvisor\n",
    "    list_local.append(full_loc_url) # store the links \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the links in the next 4 pages\n",
    "urlhead = \"https://www.tripadvisor.com/Hotels-g191-oa\" # separate the links into two parts\n",
    "urltail = \"-United_States-Hotels.html#LEAF_GEO_LIST\"   # the number between two urls will determine the page\n",
    "for i in range (20,100,20): # i receives the values: 20,40,60,80,... corresponding to pages: 2,3,4,5,...\n",
    "    url = urlhead + str(i) + urltail # the url of the page I try to scrape\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'lxml')\n",
    "    for item in soup.find_all(\"a\", attrs={\"class\":\"city\"}):\n",
    "        full_loc_url = []\n",
    "        loc_url = item.get(\"href\")\n",
    "        full_loc_url = urljoin(base_url,loc_url)\n",
    "        list_local.append(full_loc_url) # store the links in the list_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_local) # check if I get all the 100 links\n",
    "#list_local[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Retrieve the links for the first 5 pages of each location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I got the 100 location links but the links represent their first pages only.\n",
    "* For each location, I want to hotel links in the first 5 pages. There will be 500 pages in the total.\n",
    "* The code below will retrieve 500 pages and store them in full_list_local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_char = \"-\" # split the links at the \"-\" character\n",
    "                # the variable defines the page number will be at the 2nd \"-\" position\n",
    "\n",
    "for url in list_local:\n",
    "    temp = url.split(split_char)\n",
    "    for i in range (0,150,30):\n",
    "        # join the link again with the variable defining the page number in the middle\n",
    "        page_url = split_char.join(temp[:2])+ \"-oa\" + str(i) + \"-\" + split_char.join(temp[2:]) \n",
    "        full_list_local.append(page_url)\n",
    "    \n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_list_local) # check if I get all 500 pages\n",
    "#full_list_local[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Scrape the hotel links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I will write a code to scrape all the hotel links from 500 pages (~ 0 hotels per page).\n",
    "* Theoretically, I would have around 15,000 hotels but actually there are many locations with under 100 hotels.\n",
    "* The real number will be smaller than 15,000. I expect to have 10,000-13,000 hotels for my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in full_list_local:\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'lxml')\n",
    "    div = soup.find_all(\"div\", attrs={\"class\":\"listing_title\"}) # find all the div(s) that contain the href for hotels\n",
    "    \n",
    "    for item in div:\n",
    "        for i in item.find_all(\"a\"):\n",
    "            hotel_url = []\n",
    "            href_url = i.get(\"href\") # get the href(s)\n",
    "            hotel_url = urljoin(base_url,href_url) # join href(s) with the base link\n",
    "            list_hotel.append(hotel_url) # save the hotel links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_html = pd.Series(list_hotel).drop_duplicates().tolist() # drop duplicates and save them in hotel_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12313"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotel_html) # check how many hotels I will have for my dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the information from hotel pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 attributes I want to scrape in each hotel page:\n",
    "* The hotel name.\n",
    "* The location/city of the hotel.\n",
    "* Cost to stay at the hotel per night (excluding taxes and other fees).\n",
    "* TripAdvisor Score for the hotel.\n",
    "* Ratings for the hotel (excellent, good, bad,...).\n",
    "* Walk grade (0-100): shows how convenient travelers feel when moving to places near the hotel.\n",
    "* Number of nearby restaurants.\n",
    "* Number of nearby attractions.\n",
    "* State code of the hotel.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 9 empty lists to store the data\n",
    "# Some values are missing so I use the try-except here. Missing values are recorded as NAs.\n",
    "name = []\n",
    "location = []\n",
    "price = []\n",
    "score = []\n",
    "walk = []\n",
    "restaurant = []\n",
    "attraction = []\n",
    "label = []\n",
    "state = []\n",
    "\n",
    "for url in hotel_html:\n",
    "    link = requests.get(url)\n",
    "    soup = BeautifulSoup(link.content, 'lxml')\n",
    "    \n",
    "    #scrape the name\n",
    "    try:\n",
    "        nm = soup.find(\"h1\", attrs={\"class\":\"hotels-hotel-review-atf-info-parts-Heading__heading--2ZOcD\"})\n",
    "        name.append(nm.text)\n",
    "    except:\n",
    "        name.append(\"NA\")\n",
    "    \n",
    "    #scrape the location\n",
    "    try:\n",
    "        loc = soup.find(\"a\", attrs={\"data-tracking-label\":\"tourism\"})\n",
    "        location.append(loc.text)\n",
    "    except:\n",
    "        location.append(\"NA\")\n",
    "    \n",
    "    #scrape the price\n",
    "    try:\n",
    "        pc = soup.find(\"div\", attrs={\"data-sizegroup\":\"hr_chevron_prices\"})\n",
    "        price.append(pc.text)\n",
    "    except:\n",
    "        try:\n",
    "            pc = soup.find(\"div\", attrs={\"class\":\"hotels-hotel-offers-DominantOffer__price--D-ycN\"})\n",
    "            price.append(pc.text)\n",
    "        except:\n",
    "            price.append(\"NA\")\n",
    "    \n",
    "    #scrape the score\n",
    "    try:\n",
    "        scr = soup.find(\"span\", attrs={\"class\":\"hotels-hotel-review-about-with-photos-Reviews__overallRating--vElGA\"})\n",
    "        score.append(scr.text)\n",
    "    except:\n",
    "        score.append(\"NA\")\n",
    "    \n",
    "    #scrape the ratings\n",
    "    try:\n",
    "        lbl = soup.find(\"div\", attrs={\"class\":\"hotels-hotel-review-about-with-photos-Reviews__ratingLabel--24XY2\"})\n",
    "        label.append(lbl.text)\n",
    "    except:\n",
    "        label.append(\"NA\")\n",
    "    \n",
    "    #scrape the walk grade\n",
    "    try:\n",
    "        wlk = soup.find(\"span\", attrs={\"class\":\"hotels-hotel-review-location-layout-Highlight__number--S3wsZ hotels-hotel-review-location-layout-Highlight__green--3lccI\"})\n",
    "        walk.append(wlk.text)\n",
    "    except:\n",
    "        walk.append(\"NA\")\n",
    "    \n",
    "    #scrape the no. of restaurants\n",
    "    try:\n",
    "        resr = soup.find(\"span\", attrs={\"class\":\"hotels-hotel-review-location-layout-Highlight__number--S3wsZ hotels-hotel-review-location-layout-Highlight__orange--1N-BP\"})\n",
    "        restaurant.append(resr.text)\n",
    "    except:\n",
    "        restaurant.append(\"NA\")\n",
    "    \n",
    "    #scrape the no. of attractions\n",
    "    try:\n",
    "        attr = soup.find(\"span\", attrs={\"class\":\"hotels-hotel-review-location-layout-Highlight__number--S3wsZ hotels-hotel-review-location-layout-Highlight__blue--2qc3K\"})\n",
    "        attraction.append(attr.text)\n",
    "    except:\n",
    "        attraction.append(\"NA\")\n",
    "        \n",
    "    #scrape the state code\n",
    "    try:\n",
    "        st = []\n",
    "        for item in soup.find_all(\"li\" , attrs={\"class\":\"breadcrumb\"}): #this will scrape the country, location,...\n",
    "            st.append(item.text)\n",
    "        st1 = st[1] # the 2nd item will contain the state name and its code\n",
    "        st2=re.search('\\(([^)]+)', st1).group(1) #get the word within the first parenthesis\n",
    "        state.append(st2)\n",
    "    except:\n",
    "        state.append(\"NA\")\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the scrapped data in a CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(name).T\n",
    "df2 = pd.DataFrame(location).T\n",
    "df3 = pd.DataFrame(price).T\n",
    "df4 = pd.DataFrame(score).T\n",
    "df5 = pd.DataFrame(label).T\n",
    "df6 = pd.DataFrame(walk).T\n",
    "df7 = pd.DataFrame(restaurant).T\n",
    "df8 = pd.DataFrame(attraction).T\n",
    "df9 = pd.DataFrame(state).T\n",
    "df = pd.concat((df1,df2,df9,df3,df4,df5,df6,df7,df8)).T # merge the individual data into a dataframe\n",
    "df.columns = (\"Hotel\",\"Location\",\"Code\",\"Cost\",\"Score\",\"Rating\",\"Walk.Grade\",\"No. Restaurants\",\"No. Attractions\")\n",
    "df.drop_duplicates(inplace=True) # drop duplicates, fortunately, I have no duplicates after the scraping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Location</th>\n",
       "      <th>Code</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Score</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Walk.Grade</th>\n",
       "      <th>No. Restaurants</th>\n",
       "      <th>No. Attractions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Baccarat Hotel &amp; Residences New York</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NY</td>\n",
       "      <td>$1,045</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>100</td>\n",
       "      <td>451</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crowne Plaza Times Square Manhattan</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NY</td>\n",
       "      <td>$229</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>551</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Park Lane Hotel</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NY</td>\n",
       "      <td>$180</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>263</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Martinique New York on Broadway, Curio Collect...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NY</td>\n",
       "      <td>$191</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>547</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Arlo NoMad</td>\n",
       "      <td>NA</td>\n",
       "      <td>NY</td>\n",
       "      <td>$215</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>100</td>\n",
       "      <td>511</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12308</td>\n",
       "      <td>Beach Walk Oceanfront Inn</td>\n",
       "      <td>Old Orchard Beach</td>\n",
       "      <td>ME</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Very good</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12309</td>\n",
       "      <td>Moby Dick Motel</td>\n",
       "      <td>Old Orchard Beach</td>\n",
       "      <td>ME</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Very good</td>\n",
       "      <td>87</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12310</td>\n",
       "      <td>Sir Charles Motel</td>\n",
       "      <td>Old Orchard Beach</td>\n",
       "      <td>ME</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Very good</td>\n",
       "      <td>83</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12311</td>\n",
       "      <td>Sunset Motel</td>\n",
       "      <td>Old Orchard Beach</td>\n",
       "      <td>ME</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12312</td>\n",
       "      <td>Seafarer Inn and Cottages</td>\n",
       "      <td>Old Orchard Beach</td>\n",
       "      <td>ME</td>\n",
       "      <td>$125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Poor</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12313 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Hotel            Location  \\\n",
       "0                   Baccarat Hotel & Residences New York      New York City    \n",
       "1                    Crowne Plaza Times Square Manhattan      New York City    \n",
       "2                                        Park Lane Hotel      New York City    \n",
       "3      Martinique New York on Broadway, Curio Collect...      New York City    \n",
       "4                                             Arlo NoMad                  NA   \n",
       "...                                                  ...                 ...   \n",
       "12308                          Beach Walk Oceanfront Inn  Old Orchard Beach    \n",
       "12309                                    Moby Dick Motel  Old Orchard Beach    \n",
       "12310                                  Sir Charles Motel  Old Orchard Beach    \n",
       "12311                                       Sunset Motel  Old Orchard Beach    \n",
       "12312                          Seafarer Inn and Cottages  Old Orchard Beach    \n",
       "\n",
       "      Code    Cost Score     Rating Walk.Grade No. Restaurants No. Attractions  \n",
       "0       NY  $1,045   4.5  Excellent        100             451             119  \n",
       "1       NY    $229   4.0  Very good        100             551             246  \n",
       "2       NY    $180   4.0  Very good        100             263              90  \n",
       "3       NY    $191   4.0  Very good        100             547             104  \n",
       "4       NY    $215   4.5  Excellent        100             511              89  \n",
       "...    ...     ...   ...        ...        ...             ...             ...  \n",
       "12308   ME      NA   3.5  Very good         71              50               9  \n",
       "12309   ME      NA   3.5  Very good         87              57              12  \n",
       "12310   ME      NA   3.5  Very good         83              56              11  \n",
       "12311   ME      NA   3.0    Average        100              47              11  \n",
       "12312   ME    $125   2.0       Poor         62              12               1  \n",
       "\n",
       "[12313 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # show my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"TripAd-U.S_Hotels.csv\", sep='\\t') # save it in a CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
